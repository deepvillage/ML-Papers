{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ddda83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "754a2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, utils, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7606df63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x73b0149b6ed0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3e8551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79afcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "latent_dim = 20\n",
    "hidden_dim = 400\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "save_dir = \"outputs\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e37ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [02:31<00:00, 65.5kB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:02<00:00, 11.8kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:12<00:00, 135kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.0kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"mnist_data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"mnist_data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52403d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=28*28, hidden_dim=400, latent_dim=20):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # for mu and logvar\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        # decoder\n",
    "        self.fc_dec1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_dec2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (B, 784)\n",
    "        h = F.relu(self.fc1(x))\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc_dec1(z))\n",
    "        x_hat = torch.sigmoid(self.fc_dec2(h))  # Bernoulli decoder (outputs in [0,1])\n",
    "        return x_hat\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741434d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(input_dim=28*28, hidden_dim=hidden_dim, latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d8677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # recon_x and x are flattened (B, 784) with values in [0,1]\n",
    "    # Reconstruction loss: binary cross entropy (sum over pixels)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')  # sum over batch and pixels\n",
    "\n",
    "    # KL divergence between q(z|x) ~ N(mu, var) and p(z) ~ N(0,1)\n",
    "    # KL = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44baa0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_bce = 0.0\n",
    "    running_kld = 0.0\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(loader, desc=f\"Train Epoch {epoch}\", leave=False)):\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.size(0), -1)  # flatten: (B, 784)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss, bce, kld = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_bce += bce.item()\n",
    "        running_kld += kld.item()\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    avg_loss = running_loss / n\n",
    "    avg_bce = running_bce / n\n",
    "    avg_kld = running_kld / n\n",
    "    print(f\"Epoch {epoch} Train: Avg loss: {avg_loss:.4f}, BCE: {avg_bce:.4f}, KLD: {avg_kld:.4f}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf0f9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, loader, epoch, save_images=True):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_bce = 0.0\n",
    "    test_kld = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            recon, mu, logvar = model(data)\n",
    "            loss, bce, kld = loss_function(recon, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            test_bce += bce.item()\n",
    "            test_kld += kld.item()\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    avg_loss = test_loss / n\n",
    "    avg_bce = test_bce / n\n",
    "    avg_kld = test_kld / n\n",
    "    print(f\"Epoch {epoch} Eval : Avg loss: {avg_loss:.4f}, BCE: {avg_bce:.4f}, KLD: {avg_kld:.4f}\")\n",
    "\n",
    "    # save a few reconstructions and random samples\n",
    "    if save_images:\n",
    "        # Take first batch from loader to show reconstructions\n",
    "        data_sample, _ = next(iter(loader))\n",
    "        data_sample = data_sample.to(device)[:64]\n",
    "        with torch.no_grad():\n",
    "            recon_batch, _, _ = model(data_sample.view(data_sample.size(0), -1))\n",
    "        # reshape back to (B,1,28,28)\n",
    "        recons = recon_batch.view(-1, 1, 28, 28)\n",
    "        originals = data_sample\n",
    "\n",
    "        # Concatenate originals and reconstructions (first 8x8 grid)\n",
    "        comparison = torch.cat([originals[:64], recons[:64]])\n",
    "        utils.save_image(comparison.cpu(), os.path.join(save_dir, f\"recon_epoch_{epoch}.png\"), nrow=8)\n",
    "        print(f\"Saved reconstructions to {os.path.join(save_dir, f'recon_epoch_{epoch}.png')}\")\n",
    "\n",
    "        # Sample from standard normal and decode\n",
    "        z = torch.randn(64, latent_dim).to(device)\n",
    "        samples = model.decode(z).view(-1, 1, 28, 28)\n",
    "        utils.save_image(samples.cpu(), os.path.join(save_dir, f\"samples_epoch_{epoch}.png\"), nrow=8)\n",
    "        print(f\"Saved samples to {os.path.join(save_dir, f'samples_epoch_{epoch}.png')}\")\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: Avg loss: 164.5073, BCE: 149.0275, KLD: 15.4798\n",
      "Epoch 1 Eval : Avg loss: 127.7196, BCE: 106.3436, KLD: 21.3761\n",
      "Saved reconstructions to outputs/recon_epoch_1.png\n",
      "Saved samples to outputs/samples_epoch_1.png\n",
      "Saved checkpoint to outputs/vae_epoch_1.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train: Avg loss: 121.4926, BCE: 98.8286, KLD: 22.6640\n",
      "Epoch 2 Eval : Avg loss: 116.1727, BCE: 91.8081, KLD: 24.3646\n",
      "Saved reconstructions to outputs/recon_epoch_2.png\n",
      "Saved samples to outputs/samples_epoch_2.png\n",
      "Saved checkpoint to outputs/vae_epoch_2.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train: Avg loss: 114.7024, BCE: 90.4516, KLD: 24.2509\n",
      "Epoch 3 Eval : Avg loss: 112.1752, BCE: 87.4936, KLD: 24.6816\n",
      "Saved reconstructions to outputs/recon_epoch_3.png\n",
      "Saved samples to outputs/samples_epoch_3.png\n",
      "Saved checkpoint to outputs/vae_epoch_3.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train: Avg loss: 111.7953, BCE: 87.0726, KLD: 24.7227\n",
      "Epoch 4 Eval : Avg loss: 109.8246, BCE: 85.2146, KLD: 24.6100\n",
      "Saved reconstructions to outputs/recon_epoch_4.png\n",
      "Saved samples to outputs/samples_epoch_4.png\n",
      "Saved checkpoint to outputs/vae_epoch_4.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train: Avg loss: 110.0962, BCE: 85.1265, KLD: 24.9697\n",
      "Epoch 5 Eval : Avg loss: 108.7950, BCE: 84.1767, KLD: 24.6184\n",
      "Saved reconstructions to outputs/recon_epoch_5.png\n",
      "Saved samples to outputs/samples_epoch_5.png\n",
      "Saved checkpoint to outputs/vae_epoch_5.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train: Avg loss: 108.9465, BCE: 83.8546, KLD: 25.0920\n",
      "Epoch 6 Eval : Avg loss: 107.7246, BCE: 82.9583, KLD: 24.7663\n",
      "Saved reconstructions to outputs/recon_epoch_6.png\n",
      "Saved samples to outputs/samples_epoch_6.png\n",
      "Saved checkpoint to outputs/vae_epoch_6.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train: Avg loss: 108.0764, BCE: 82.9074, KLD: 25.1690\n",
      "Epoch 7 Eval : Avg loss: 107.1779, BCE: 82.2500, KLD: 24.9278\n",
      "Saved reconstructions to outputs/recon_epoch_7.png\n",
      "Saved samples to outputs/samples_epoch_7.png\n",
      "Saved checkpoint to outputs/vae_epoch_7.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train: Avg loss: 107.4345, BCE: 82.1987, KLD: 25.2357\n",
      "Epoch 8 Eval : Avg loss: 106.5124, BCE: 81.3601, KLD: 25.1523\n",
      "Saved reconstructions to outputs/recon_epoch_8.png\n",
      "Saved samples to outputs/samples_epoch_8.png\n",
      "Saved checkpoint to outputs/vae_epoch_8.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train: Avg loss: 106.9065, BCE: 81.6318, KLD: 25.2747\n",
      "Epoch 9 Eval : Avg loss: 106.2970, BCE: 81.1830, KLD: 25.1140\n",
      "Saved reconstructions to outputs/recon_epoch_9.png\n",
      "Saved samples to outputs/samples_epoch_9.png\n",
      "Saved checkpoint to outputs/vae_epoch_9.pt\n",
      "New best model saved to outputs/vae_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: Avg loss: 106.5062, BCE: 81.1640, KLD: 25.3422\n",
      "Epoch 10 Eval : Avg loss: 105.8104, BCE: 80.7437, KLD: 25.0667\n",
      "Saved reconstructions to outputs/recon_epoch_10.png\n",
      "Saved samples to outputs/samples_epoch_10.png\n",
      "Saved checkpoint to outputs/vae_epoch_10.pt\n",
      "New best model saved to outputs/vae_best.pt\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "best_val = float(\"inf\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, epoch)\n",
    "    val_loss = eval_epoch(model, test_loader, epoch, save_images=True)\n",
    "\n",
    "    # Save model checkpoint\n",
    "    ckpt_path = os.path.join(save_dir, f\"vae_epoch_{epoch}.pt\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ea6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
